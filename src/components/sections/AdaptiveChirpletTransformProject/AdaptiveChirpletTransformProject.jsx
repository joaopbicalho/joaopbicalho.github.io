import React from "react";
import "katex/dist/katex.min.css";
import { InlineMath, BlockMath } from "react-katex";

const ChirpletThesis = () => {
  return (
    <div className="project-detail">
      <div className="project-header">
        <h1>Adaptive Chirplet Transform and Deep Learning Algorithms for EEG-based Sleep Stage Detection</h1>
        <p className="project-subtitle">
          Exploring the potential of ACT as a feature extraction method for EEG-based sleep stage classification.
        </p>
      </div>

      <div className="project-content">
        {/* Extended Background */}
        <section className="project-section">
          <h2>Background</h2>
          <p>
            Time-frequency analysis is essential for understanding signals whose spectral content evolves over time — 
            such as EEG, speech, radar, and animal communication. While traditional methods like the Short-Time Fourier Transform (STFT)
            and Wavelet Transform offer fixed-resolution representations, they often fall short when dealing with complex,
            non-stationary signals where both time and frequency vary continuously.
          </p>
          <p>
            The <strong>Chirplet Transform</strong> generalizes wavelet and Fourier bases by introducing a chirp rate, allowing atoms to
            follow linear frequency modulations. This makes it especially powerful in representing signals with time-varying spectral slopes.
            The <strong>Adaptive Chirplet Transform (ACT)</strong> goes one step further by selecting a set of chirplet atoms optimized for 
            sparsity and signal fidelity.
          </p>

          <div className="equation-box">
            <p>Chirplet Atom:</p>
            <BlockMath math={"\\psi(t) = A \\cdot e^{j(2\\pi f_0 t + \\pi c t^2)} \\cdot e^{-t^2 / (2\\sigma^2)}"} />
            <p>
              where <InlineMath math={"f_0"} /> is the center frequency, <InlineMath math={"c"} /> the chirp rate, and <InlineMath math={"\\sigma"} /> the time spread.
            </p>
          </div>

          <div className="equation-box">
            <p>Chirplet Transform:</p>
            <BlockMath math={"C_x(f_0, c, \\sigma, \\tau) = \\int x(t) \\cdot \\psi^*_{f_0, c, \\sigma, \\tau}(t) \\, dt"} />
            <p>
              where <InlineMath math={"\\psi^*"} /> is the complex conjugate of the chirplet atom centered at <InlineMath math={"\\tau"} />.
            </p>
          </div>

          <h3>EEG Analysis Challenges</h3>
          <p>
            Electroencephalography (EEG) measures the electrical activity generated by the brain, detecting minute differences in electric potential at the scalp. 
            These signals result from the collective activity of post-synaptic potentials produced by neurons within the cortical layers. However, EEG signals 
            are highly complex due to their non-stationary nature, low signal-to-noise ratio, and the presence of artifacts from non-neural sources.
          </p>
          <p>
            Traditional methods in EEG analysis include Event-Related Potentials (ERPs), which identify brain responses time-locked to specific events, 
            and spectral analysis, which focuses on frequency content across delta, theta, alpha, beta, and gamma bands. Each frequency band correlates 
            with distinct cognitive and physiological states, such as delta waves linked to deep sleep or alpha waves associated with relaxation.
          </p>

          <h3>ACT Development and Applications</h3>
          <p>
            The ACT was originally developed by S. Mann and S. Haykin in 1991, with subsequent modifications proposed by various researchers. Notable examples 
            include the "Adaptive Linear Chirplet Transform" by Guan et al., the "Multi-Synchronizing Chirplet Transform" by Zhu et al., and the "Enhanced 
            Adaptive Linear Chirplet Transform" (EALCT) by López et al.
          </p>
          <p>
            Given its flexibility and capability to capture information from signals that vary both in time and frequency, the ACT has been applied across 
            a wide range of applications: aircraft bearing fault diagnosis, P300 and VEP detection in EEG, epileptic seizure detection, and target recognition 
            from RADAR technology.
          </p>
        </section>

        {/* Goals & Contributions */}
        <section className="project-section">
          <h2>Goals and Contributions</h2>
          <ul>
            <li>Implemented a robust pipeline for applying ACT to real-world EEG signals for sleep stage detection</li>
            <li>Developed GPU-accelerated implementation of ACT using CuPy for large-scale EEG processing</li>
            <li>Optimized chirplet dictionary parameters for 15-second EEG epochs with 75% overlap</li>
            <li>Created hybrid CNN-GRU architecture for processing ACT-transformed features</li>
            <li>Demonstrated ACT's compression capabilities with 153.6:1 ratio while maintaining signal fidelity</li>
            <li>Validated approach on Bitbrain Open Access Sleep Database with expert-labeled sleep stages</li>
          </ul>
        </section>

        {/* Database Used - New Comprehensive Section */}
        <section className="project-section">
          <h2>Database Used: Bitbrain Open Access Sleep Database</h2>
          <p>
            The Bitbrain Open Access Sleep Database was carefully selected for this study due to its exceptional quality labeling procedure and 
            abundant sleep data. This dataset provided a reliable foundation for training and validating machine learning models with high-quality 
            ground truth labels for comparison.
          </p>
          
          <h3>Dataset Specifications</h3>
          <ul>
            <li><strong>Scale:</strong> 128 full nights of sleep data from 108 participants</li>
            <li><strong>Data Types:</strong> Polysomnography (PSG) data, EEG recordings, and comprehensive sleep stage labels</li>
            <li><strong>Sleep Stages:</strong> Wake, NonREM sleep stages 1-3, REM sleep, PSG disconnection, and artifact/missing data labels</li>
            <li><strong>Temporal Resolution:</strong> Labels provided for 30-second epochs</li>
          </ul>

          <h3>Expert Labeling Protocol</h3>
          <p>
            The labeling process followed rigorous scientific standards to ensure data quality. Three expert sleep scorers independently 
            analyzed each recording, following criteria developed by the Academy of Sleep Medicine. Labels required agreement from at least 
            two of the three scorers. In cases where consensus was not achieved, a fourth expert was brought in to make the final decision.
          </p>
          <p>
            This multi-expert approach was designed to reduce human error and disagreement in sleep scoring, addressing the inherent variability 
            between experts when classifying sleep stages. Research indicates that inter-scorer agreement is approximately 85%, making this 
            consensus-based approach crucial for reliable ground truth labels.
          </p>

          <h3>Data Processing Considerations</h3>
          <p>
            Due to computational constraints and GPU costs, this research processed 3 out of the 128 available nights of sleep data. 
            Despite this limitation, the 75% epoch overlap strategy generated over 12,000 epochs, resulting in 10,633 samples after 
            preprocessing and quality filtering. This subset provided sufficient data for training and validating the deep learning model 
            while demonstrating the ACT's potential for larger-scale applications.
          </p>
        </section>

        {/* Comprehensive Methodology */}
        <section className="project-section">
          <h2>Methodology</h2>
          
          <h3>Preprocessing Pipeline</h3>
          <p>
            A comprehensive Python pipeline was developed for EEG data preprocessing using the MNE library, the most commonly used Python 
            package for EEG and MEG data analysis. The preprocessing included several critical steps to ensure signal quality while preserving 
            physiological features necessary for sleep stage classification.
          </p>
          
          <h4>Filtering Strategy</h4>
          <ul>
            <li><strong>Bandpass Filter:</strong> 1-40 Hz using zero-phase FIR filter with Hamming window</li>
            <li><strong>Notch Filter:</strong> 50 Hz to eliminate power line interference</li>
            <li><strong>Filter Design:</strong> FIR filters chosen for stability, well-defined passband, and zero-phase correction capabilities</li>
          </ul>

          <h4>Windowing and Overlap Strategy</h4>
          <p>
            EEG signals were segmented into overlapping epochs of 15 seconds with 75% overlap. Multiple window functions were evaluated, 
            including Dirichlet, Bartlett, Hann, Hamming, Blackman, and Kaiser windows. The Hamming window was selected for its optimal 
            balance of computational efficiency, main-lobe width, and side-lobe suppression.
          </p>
          <p>
            The 75% overlap strategy was implemented to mitigate edge degradation effects, ensuring each time point was well-represented 
            in at least one central region of a window where approximation quality is highest.
          </p>

          <div className="setup-image-container">
            <img
              src="/media/act_window.png"
              alt="Effect of Hamming Window on Signal Approximation"
              width={600}
              height={400}
              className="setup-image"
            />
          </div>

          <h3>ACT Parameter Optimization</h3>
          <p>
            The chirplet dictionary generation required careful parameter tuning to balance computational requirements with signal 
            approximation accuracy. Parameters were optimized through extensive testing and visualization of reconstruction quality.
          </p>
          
          <div className="equation-box">
            <p>General Gaussian Chirplet:</p>
            <BlockMath math={"g(t) = \\frac{1}{\\sqrt[4]{\\pi} \\sqrt{\\Delta t}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{t-t_c}{\\Delta t}\\right)^2 + j \\cdot 2\\pi [c(t-t_c) + f_c(t-t_c)]\\right)"} />
          </div>

          <p>
            Parameters: <InlineMath math={"t_c"} /> (center time), <InlineMath math={"\\Delta t"} /> (duration), <InlineMath math={"c"} /> (chirp rate), <InlineMath math={"f_c"} /> (center frequency)
          </p>

          <h4>Final Parameter Ranges:</h4>
          <ul>
            <li><strong>Time:</strong> tc ∈ [0, 3840] samples (15 seconds at 256 Hz) in steps of 64</li>
            <li><strong>Frequency:</strong> fc ∈ [0.6, 15] Hz in steps of 0.2</li>
            <li><strong>Dictionary Size:</strong> Over 1.4 million Gaussian chirplet functions</li>
          </ul>

          <div className="setup-image-container">
            <img
              src="/images/act-diagram.png"
              alt="Adaptive Chirplet Transform Process Diagram"
              width={800}
              height={400}
              className="setup-image"
            />
          </div>
        </section>

        {/* GPU Implementation - New Comprehensive Section */}
        <section className="project-section">
          <h2>GPU Implementation and Computational Optimization</h2>
          
          <h3>Computational Challenges</h3>
          <p>
            The original CPU-based implementation of the Adaptive Chirplet Transform proved impractical for large-scale EEG processing. 
            With dictionary sizes exceeding 1.4 million chirplet functions and the need to process thousands of epochs with high overlap, 
            computational requirements became prohibitive for standard desktop systems.
          </p>

          <h3>CuPy-Based GPU Acceleration</h3>
          <p>
            To address these limitations, the entire ACT pipeline was rewritten using CuPy, a library that mirrors NumPy's interface 
            while executing operations on GPU hardware. This transition enabled massive parallelization of the computationally intensive 
            dictionary matching and optimization processes.
          </p>

          <h4>Implementation Details:</h4>
          <ul>
            <li><strong>Hardware:</strong> NVIDIA A100 SXM4 GPU with 40 GB VRAM via Lambda Labs</li>
            <li><strong>Memory Management:</strong> Entire EEG signals and chirplet dictionaries loaded into GPU memory</li>
            <li><strong>Parallel Processing:</strong> Epoch segmentation, windowing, and chirplet projections executed in parallel</li>
            <li><strong>Data Transfer Optimization:</strong> Minimal CPU-GPU data movement, only final results transferred back</li>
          </ul>

          <h3>Performance Metrics</h3>
          <p>
            Despite significant GPU optimizations, computational complexity remained substantial. Processing 3 nights of sleep data 
            (equivalent to ~24 hours of EEG recordings) required 33.4 hours of A100 GPU time at a cost of $43.11. This translates 
            to approximately 11 hours of GPU processing for every 8 hours of EEG data.
          </p>
          
          <h4>Output Data Characteristics:</h4>
          <ul>
            <li><strong>File Size:</strong> ~900 MB CSV files per night of sleep</li>
            <li><strong>Compression Achieved:</strong> 153.6:1 ratio (3,840 samples → 25 features per epoch)</li>
            <li><strong>Data Retention:</strong> 0.651% of original signal preserved</li>
          </ul>

          <h3>Scalability Considerations</h3>
          <p>
            While the GPU implementation made full-night EEG processing feasible, computational complexity remains the primary barrier 
            to widespread ACT adoption. Processing the complete Bitbrain dataset (128 nights) would require approximately 1,400 GPU hours, 
            highlighting the need for further algorithmic optimizations or specialized hardware solutions.
          </p>
        </section>

        {/* Neural Networks - New Comprehensive Section */}
        <section className="project-section">
          <h2>Deep Learning Architecture: CNN-GRU Hybrid Model</h2>
          
          <h3>Input Data Preparation</h3>
          <p>
            The ACT output required careful restructuring to optimize neural network performance. Each epoch's ACT results were 
            transformed into a 5×5 matrix representation, where rows correspond to different ACT orders and columns contain 
            coefficients and the four defining chirplet parameters.
          </p>

          <h4>Data Preprocessing Steps:</h4>
          <ul>
            <li><strong>Matrix Restructuring:</strong> Coefficients and parameters organized into 5×5 matrices</li>
            <li><strong>Label Synchronization:</strong> ACT epochs mapped back to original 30-second labeled epochs</li>
            <li><strong>Transition Period Handling:</strong> Epochs spanning sleep stage transitions were excluded</li>
            <li><strong>Class Filtering:</strong> Removed rare classes (PSG disconnected, N3, artifacts) with &lt;0.1% representation</li>
          </ul>

          <h3>Model Architecture</h3>
          <p>
            A hybrid CNN-GRU architecture was designed to capture both spatial patterns within ACT feature matrices and 
            temporal dependencies across sequential epochs. This approach leverages the strengths of both convolutional and 
            recurrent neural networks for time-series classification.
          </p>

          <h4>CNN Component:</h4>
          <ul>
            <li><strong>Input Shape:</strong> 1×5×5 (channels × height × width) per time step</li>
            <li><strong>Convolutional Layer:</strong> 16 output channels, 3×3 kernel with padding</li>
            <li><strong>Spatial Feature Extraction:</strong> Captures local patterns between chirplet features</li>
            <li><strong>Output:</strong> 400-dimensional feature vectors per time step</li>
          </ul>

          <h4>GRU Component:</h4>
          <ul>
            <li><strong>Architecture:</strong> 2 stacked layers with 64 hidden units each</li>
            <li><strong>Sequence Processing:</strong> Models temporal dependencies across 4-epoch sequences</li>
            <li><strong>Memory Mechanism:</strong> Captures sleep stage transition patterns and temporal consistency</li>
            <li><strong>Output:</strong> Final hidden state used for classification</li>
          </ul>

          <h3>Training Strategy</h3>
          <p>
            The model employed several strategies to address the inherent challenges of sleep stage classification, 
            particularly class imbalance and temporal dependencies.
          </p>

          <h4>Data Balancing:</h4>
          <ul>
            <li><strong>Stratified Splitting:</strong> 70% training, 15% validation, 15% test with preserved class distributions</li>
            <li><strong>Training Set Oversampling:</strong> Classes balanced to equal representation during training</li>
            <li><strong>Validation/Test Preservation:</strong> Original class distributions maintained for realistic performance evaluation</li>
          </ul>

          <h4>Training Configuration:</h4>
          <ul>
            <li><strong>Loss Function:</strong> Cross-entropy with class weights to address residual imbalance</li>
            <li><strong>Optimizer:</strong> Adam with learning rate of 0.001</li>
            <li><strong>Batch Processing:</strong> Batch size of 8 with sequence length of 4 epochs</li>
            <li><strong>Feature Standardization:</strong> StandardScaler applied for zero mean and unit variance</li>
          </ul>

          <h3>Temporal Sequence Processing</h3>
          <p>
            The model incorporated temporal context by processing sequences of 4 consecutive epochs. This approach leverages 
            the biological reality that sleep stages typically persist for several minutes, allowing previous epochs to inform 
            current classifications. Sequences were shuffled before train/validation/test splitting to ensure model generalization.
          </p>
        </section>

        {/* Comprehensive Results */}
        <section className="project-section">
          <h2>Results and Analysis</h2>
          
          <h3>Model Performance</h3>
          <p>
            The CNN-GRU hybrid model demonstrated strong learning capability with a training accuracy of 91.54% after 100 epochs. 
            This high training performance validates the hypothesis that the Adaptive Chirplet Transform effectively captures 
            discriminative features for sleep stage classification.
          </p>

          <div className="results-image-container">
            <img
              src="/media/confusion_matrix.png"
              alt="Confusion Matrix - Final Model Results"
              width={300}
              height={200}
              className="results-image"
            />
          </div>

          <h4>Performance Metrics:</h4>
          <ul>
            <li><strong>Training Accuracy:</strong> 91.54%</li>
            <li><strong>Validation Accuracy:</strong> 52.76%</li>
            <li><strong>Test Accuracy:</strong> 57.93%</li>
            <li><strong>Compression Ratio:</strong> 153.6:1</li>
            <li><strong>Data Retention:</strong> 0.651% of original signal</li>
          </ul>

          <h3>Compression Analysis</h3>
          <p>
            The ACT achieved remarkable compression while maintaining signal fidelity. Each 15-second epoch containing 3,840 sample 
            points was represented using only 25 floating-point values (coefficients and parameters).
          </p>

          <div className="equation-box">
            <p>Compression Ratio:</p>
            <BlockMath math={"\\text{CR} = \\frac{\\text{Original size}}{\\text{Compressed size}} = \\frac{3840}{25} = 153.6:1"} />
          </div>

          <div className="equation-box">
            <p>Compression Rate:</p>
            <BlockMath math={"\\text{Rate} = \\frac{25}{3840} \\approx 0.00651 = 0.651\\% \\text{ of original data retained}"} />
          </div>

          <h3>Class-Specific Analysis</h3>
          <p>
            The confusion matrix revealed important patterns in model behavior. N2 sleep stage, being the most prevalent class 
            (1,133 test samples), achieved the highest number of correct predictions (682). However, this dominance led to 
            prediction bias, with other classes frequently misclassified as N2.
          </p>

          <h4>Classification Patterns:</h4>
          <ul>
            <li><strong>Wake → N2:</strong> 115 misclassifications, indicating difficulty distinguishing quiet wakefulness</li>
            <li><strong>REM → N2:</strong> 58 misclassifications, suggesting feature overlap between stages</li>
            <li><strong>N1 Performance:</strong> Only 1 correct classification, highlighting extreme class imbalance effects</li>
            <li><strong>N2 Bias:</strong> Model defaulted to dominant class when uncertain</li>
          </ul>

          <h3>Performance Context</h3>
          <p>
            While test accuracy appears modest compared to some EEG classification studies, it's important to consider the 
            complexity of sleep stage detection. Inter-expert agreement in manual sleep scoring typically achieves ~85% accuracy, 
            providing important context for automated system performance expectations.
          </p>
        </section>

        {/* Tools and Technologies */}
        <section className="project-section">
          <h2>Tools and Technologies</h2>
          <ul>
            <li><strong>Signal Processing:</strong> Python, NumPy, SciPy, MNE-Python for EEG preprocessing</li>
            <li><strong>GPU Computing:</strong> CuPy for GPU-accelerated ACT implementation</li>
            <li><strong>Deep Learning:</strong> PyTorch for CNN-GRU hybrid model development</li>
            <li><strong>Data Analysis:</strong> Pandas, scikit-learn for data manipulation and model evaluation</li>
            <li><strong>Visualization:</strong> Matplotlib, seaborn for result visualization and analysis</li>
            <li><strong>Hardware:</strong> NVIDIA A100 GPU via Lambda Labs cloud computing</li>
            <li><strong>Dataset:</strong> Bitbrain Open Access Sleep Database</li>
          </ul>
        </section>

        {/* Comprehensive Future Work */}
        <section className="project-section">
          <h2>Future Work and Optimization Strategies</h2>
          
          <h3>Computational Optimization</h3>
          <p>
            The primary limitation of the current ACT implementation remains computational complexity. With dictionary sizes 
            exceeding 1.4 million chirplet functions, processing time scales prohibitively with data volume. Several optimization 
            strategies could address this challenge:
          </p>

          <h4>Dictionary Optimization Approaches:</h4>
          <ul>
            <li><strong>Adaptive Dictionary Generation:</strong> Create dictionaries from frequently selected chirplets rather than exhaustive parameter sweeps</li>
            <li><strong>Hierarchical Search:</strong> Implement coarse-to-fine parameter optimization to reduce search space</li>
            <li><strong>Learning-Based Selection:</strong> Train neural networks to predict optimal chirplet parameters</li>
            <li><strong>Sparse Dictionary Methods:</strong> Apply compressed sensing techniques to reduce dictionary size</li>
          </ul>

          <h3>Scalability Improvements</h3>
          <p>
            Expanding to the full Bitbrain dataset (128 nights) could significantly improve model generalization and address 
            class imbalance issues. This would require approximately 1,400 GPU hours but could provide the data volume necessary 
            for robust deep learning model training.
          </p>

          <h3>Architecture Enhancements</h3>
          <h4>Model Architecture Improvements:</h4>
          <ul>
            <li><strong>Transformer Integration:</strong> Replace GRU with self-attention mechanisms for better long-range dependencies</li>
            <li><strong>Multi-Scale Processing:</strong> Incorporate multiple temporal resolutions for improved feature extraction</li>
            <li><strong>Attention Mechanisms:</strong> Add spatial and temporal attention to focus on most relevant ACT features</li>
            <li><strong>Ensemble Methods:</strong> Combine multiple models trained on different ACT parameter configurations</li>
          </ul>

          <h3>Real-Time Applications</h3>
          <p>
            The current processing time of 11 hours per 8 hours of EEG data prevents real-time applications. Future work should 
            target sub-second processing times to enable online sleep monitoring and brain-computer interface applications where 
            the ACT's compression capabilities would be particularly valuable.
          </p>

          <h3>Clinical Translation</h3>
          <p>
            Beyond computational improvements, clinical validation studies would be necessary to translate this research into 
            practical sleep monitoring systems. This includes validation across diverse populations, comparison with existing 
            clinical tools, and integration with portable EEG devices for home sleep studies.
          </p>
        </section>


        {/* Conclusion */}
        <section className="project-section">
          <h2>Conclusion</h2>
          <p>
            This thesis demonstrates that the Adaptive Chirplet Transform has significant potential as a feature extraction method 
            for EEG-based deep learning applications. The ACT successfully compressed EEG signals with a 153.6:1 ratio while 
            maintaining sufficient information for sleep stage classification, achieving 91.5% training accuracy.
          </p>
          <p>
            The GPU-accelerated implementation proved essential for processing large-scale EEG datasets, though computational 
            complexity remains a barrier to widespread adoption. The CNN-GRU hybrid architecture effectively leveraged ACT features 
            for temporal classification, though class imbalance limited generalization performance.
          </p>
          <p>
            With continued optimization of dictionary generation and expanded training data, the ACT could become a powerful 
            standard for EEG signal processing, particularly valuable for resource-constrained applications like brain-computer 
            interfaces where its exceptional compression capabilities would provide significant advantages.
          </p>
        </section>
      </div>
    </div>
  );
};

export default ChirpletThesis;
